#
# Software Copyright BAE Systems plc 2017. All Rights Reserved.
# BAE SYSTEMS, DETICA are trademarks of BAE Systems
# plc and may be registered in certain jurisdictions.
#
---
# vars file for single_node_vm blueprint

hive_components: [HIVE_METASTORE,HIVE_SERVER,HCAT,WEBHCAT_SERVER,HIVE_CLIENT,MYSQL_SERVER]
hadoop_components: [APP_TIMELINE_SERVER,NODEMANAGER,SECONDARY_NAMENODE,MAPREDUCE2_CLIENT,DATANODE,NAMENODE,HDFS_CLIENT,HISTORYSERVER,YARN_CLIENT,RESOURCEMANAGER]
oozie_components: [OOZIE_CLIENT,OOZIE_SERVER]
zookeeper_components: [ZOOKEEPER_SERVER,ZOOKEEPER_CLIENT]
other_components: [TEZ_CLIENT]
metric_components: [METRICS_COLLECTOR,METRICS_MONITOR]
spark_components: [SPARK_JOBHISTORYSERVER,SPARK_CLIENT]
cr_components: "{{ hadoop_components | union (zookeeper_components) | union(oozie_components) | union(hive_components) | union(metric_components) | union(spark_components) | union(other_components) }}"

cluster_name: "mdr"
blueprint_name: "mdr_blueprint"

configurations:
  - zoo.cfg:
      autopurge.purgeInterval: 24
      dataDir: /hadoop/zookeeper
      autopurge.snapRetainCount: 30
      clientPort: 2181
      initLimit: 10
      tickTime: 2000
      syncLimit: 5
  - oozie-env:
      oozie_user_nproc_limit: 16000
      oozie_pid_dir: /var/run/oozie
      oozie_user_nofile_limit: 32000
      oozie_log_dir: /var/log/oozie
      oozie_tmp_dir: /var/tmp/oozie
      oozie_admin_port: 11001
      oozie_heapsize: 2048m
      oozie_data_dir: /hadoop/oozie/data
      oozie_user: oozie
      oozie_admin_users: '{oozie_user}, oozie-admin'
      oozie_database: 'New Derby Database'
      oozie_permsize: 256m
  - hadoop-policy:
      security.inter.datanode.protocol.acl: '*'
      security.refresh.usertogroups.mappings.protocol.acl: hadoop
      security.admin.operations.protocol.acl: hadoop
      security.client.datanode.protocol.acl: '*'
      security.datanode.protocol.acl: '*'
      security.inter.tracker.protocol.acl: '*'
      security.job.client.protocol.acl: '*'
      security.client.protocol.acl: '*'
      security.job.task.protocol.acl: '*'
      security.refresh.policy.protocol.acl: hadoop
      security.namenode.protocol.acl: '*'
  - tez-interactive-site:
      tez.runtime.pipelined.sorter.lazy-allocate.memory: 'true'
      tez.runtime.report.partition.stats: 'true'
      ez.runtime.shuffle.fetch.buffer.percent: 0.6
      tez.session.am.dag.submit.timeout.secs: 3600
      tez.dag.recovery.enabled: 'false'
      tez.am.resource.memory.mb: 1536
      tez.lib.uris: "/hdp/apps/${hdp.version}/tez_hive2/tez.tar.gz"
      tez.grouping.node.local.only: 'true'
      tez.runtime.shuffle.memory.limit.percent: 0.25
      tez.runtime.pipelined-shuffle.enabled: 'false'
      tez.runtime.shuffle.fetch.verify-disk-checksum: 'false'
  - core-site:
      fs.defaultFS: "hdfs://%HOSTGROUP::host_group_1%:8020"
      ipc.server.tcpnodelay: 'true'
      mapreduce.jobtracker.webinterface.trusted: 'false'
      hadoop.security.auth_to_local: DEFAULT
      hadoop.proxyuser.root.groups: '*'
      ipc.client.idlethreshold: 8000
      hadoop.proxyuser.hdfs.groups: '*'
      fs.trash.interval: 360
      hadoop.http.authentication.simple.anonymous.allowed: 'true'
      hadoop.security.authorization: 'false'
      ipc.client.connection.maxidletime: 30000
      hadoop.proxyuser.hcat.groups: '*'
      hadoop.proxyuser.livy.groups: '*'
      hadoop.proxyuser.hive.hosts: "%HOSTGROUP::host_group_1%"
      hadoop.proxyuser.root.hosts: '{{ ambari_host }}'
      ha.failover-controller.active-standby-elector.zk.op.retries: 120
      hadoop.security.authentication: simple
      hadoop.proxyuser.hdfs.hosts: '*'
      ipc.client.connect.max.retries: 50
      io.file.buffer.size: 131072
      hadoop.proxyuser.livy.hosts: '*'
      hadoop.proxyuser.oozie.hosts: "%HOSTGROUP::host_group_1%"
      hadoop.proxyuser.hcat.hosts: "%HOSTGROUP::host_group_1%"
      hadoop.proxyuser.oozie.groups: '*'
      net.topology.script.file.name: /etc/hadoop/conf/topology_script.py
      io.compression.codecs: org.apache.hadoop.io.compress.GzipCodec,org.apache.hadoop.io.compress.DefaultCodec,org.apache.hadoop.io.compress.SnappyCodec
      hadoop.proxyuser.hive.groups: '*'
      io.serializations: org.apache.hadoop.io.serializer.WritableSerialization
  - hdfs-site:
      dfs.replication: 3
      dfs.namenode.audit.log.async: 'true'
      dfs.namenode.checkpoint.dir: /hadoop/hdfs/namesecondary
      dfs.namenode.avoid.read.stale.datanode: 'true'
      dfs.journalnode.http-address: 0.0.0.0:8480
      nfs.file.dump.dir: /tmp/.hdfs-nfs
      dfs.namenode.rpc-address: "%HOSTGROUP::host_group_1%:8020"
      dfs.namenode.https-address: "%HOSTGROUP::host_group_1%:50470"
      dfs.encrypt.data.transfer.cipher.suites: AES/CTR/NoPadding
      dfs.client.read.shortcircuit.streams.cache.size: 4096
      dfs.hosts.exclude: /etc/hadoop/conf/dfs.exclude
      dfs.namenode.accesstime.precision: 0
      dfs.namenode.fslock.fair: 'false'
      dfs.permissions.enabled: 'true'
      dfs.datanode.balance.bandwidthPerSec: 6250000
      dfs.namenode.stale.datanode.interval: 30000
      dfs.content-summary.limit: 5000
      dfs.http.policy: HTTP_ONLY
      dfs.journalnode.https-address: 0.0.0.0:8481
      dfs.datanode.du.reserved: 5074662912
      dfs.domain.socket.path: /var/lib/hadoop-hdfs/dn_socket
      dfs.datanode.ipc.address: 0.0.0.0:8010
      dfs.cluster.administrators:  hdfs
      dfs.datanode.max.transfer.threads: 4096
      dfs.namenode.handler.count: 100
      dfs.https.port: 50470
      dfs.replication.max: 50
      dfs.client.read.shortcircuit: 'true'
      dfs.webhdfs.enabled: 'true'
      dfs.namenode.http-address: '%HOSTGROUP::host_group_1%:50070'
      dfs.namenode.name.dir: /hadoop/hdfs/namenode
      dfs.namenode.avoid.write.stale.datanode: 'true'
      dfs.datanode.https.address: 0.0.0.0:50475
      dfs.datanode.failed.volumes.tolerated: 0
      dfs.client.retry.policy.enabled: 'false'
      dfs.namenode.startup.delay.block.deletion.sec: 3600
      dfs.block.access.token.enable: 'true'
      dfs.datanode.data.dir: /hadoop/hdfs/data
      dfs.permissions.superusergroup: hdfs
      dfs.blocksize: 134217728
      dfs.namenode.checkpoint.edits.dir: ${dfs.namenode.checkpoint.dir}
      nfs.exports.allowed.hosts: '* rw'
      dfs.datanode.address: 0.0.0.0:50010
      dfs.blockreport.initialDelay: 120
      dfs.datanode.data.dir.perm: 750
      dfs.namenode.write.stale.datanode.ratio: 1.0f
      dfs.namenode.name.dir.restore: 'true'
      dfs.heartbeat.interval: 3
      dfs.namenode.secondary.http-address: '%HOSTGROUP::host_group_1%:50090'
      dfs.namenode.checkpoint.txns: 1000000
      dfs.journalnode.edits.dir: /hadoop/hdfs/journalnode
      dfs.support.append: 'true'
      fs.permissions.umask-mode: '022'
      dfs.namenode.safemode.threshold-pct: 1
      dfs.namenode.checkpoint.period: 21600
      dfs.datanode.http.address: 0.0.0.0:50075
  - yarn-site:
      yarn.resourcemanager.zk-address: '%HOSTGROUP::host_group_1%:2181'
      yarn.nodemanager.container-monitor.interval-ms: 3000
      yarn.timeline-service.entity-group-fs-store.active-dir: /ats/active/
      yarn.nodemanager.linux-container-executor.group: hadoop
      yarn.application.classpath: '$HADOOP_CONF_DIR,/usr/hdp/current/hadoop-client/*,/usr/hdp/current/hadoop-client/lib/*,/usr/hdp/current/hadoop-hdfs-client/*,/usr/hdp/current/hadoop-hdfs-client/lib/*,/usr/hdp/current/hadoop-yarn-client/*,/usr/hdp/current/hadoop-yarn-client/lib/*'
      yarn.admin.acl: yarn
      yarn.timeline-service.entity-group-fs-store.cleaner-interval-seconds: 3600
      yarn.nodemanager.remote-app-log-dir-suffix: logs
      yarn.nodemanager.address: 0.0.0.0:45454
      yarn.resourcemanager.webapp.address: '%HOSTGROUP::host_group_1%:8088'
      yarn.timeline-service.leveldb-timeline-store.ttl-interval-ms: 300000
      yarn.scheduler.maximum-allocation-vcores: 3
      yarn.timeline-service.address: '%HOSTGROUP::host_group_1%:10200'
      yarn.timeline-service.enabled: 'true'
      yarn.nodemanager.aux-services: mapreduce_shuffle
      yarn.nodemanager.resource.cpu-vcores: 3
      yarn.resourcemanager.webapp.delegation-token-auth-filter.enabled: 'false'
      yarn.nodemanager.log-aggregation.debug-enabled: 'false'
      yarn.resourcemanager.zk-acl: world:anyone:rwcda
      yarn.client.nodemanager-connect.max-wait-ms: 60000
      yarn.http.policy: HTTP_ONLY
      yarn.timeline-service.http-authentication.simple.anonymous.allowed: 'true'
      yarn.resourcemanager.zk-state-store.parent-path: /rmstore
      yarn.timeline-service.leveldb-timeline-store.start-time-read-cache-size: 10000
      yarn.resourcemanager.admin.address: '%HOSTGROUP::host_group_1%:8141'
      yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage: 'false'
      yarn.resourcemanager.resource-tracker.address: '%HOSTGROUP::host_group_1%:8025'
      yarn.nodemanager.delete.debug-delay-sec: 0
      yarn.resourcemanager.fs.state-store.retry-policy-spec: 2000, 500
      yarn.timeline-service.http-authentication.type: simple
      yarn.timeline-service.ttl-enable: 'true'
      yarn.timeline-service.entity-group-fs-store.retain-seconds: 604800
      yarn.log-aggregation.retain-seconds: 2592000
      yarn.nodemanager.resource.memory-mb: 8192
      yarn.nodemanager.disk-health-checker.min-healthy-disks: 0.25
      yarn.node-labels.enabled: 'false'
      yarn.nodemanager.log.retain-second: 604800
      yarn.resourcemanager.connect.max-wait.ms: 900000
      yarn.resourcemanager.zk-num-retries: 1000
      yarn.scheduler.minimum-allocation-vcores: 1
      yarn.resourcemanager.scheduler.class: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
      yarn.resourcemanager.system-metrics-publisher.enabled: 'true'
      yarn.timeline-service.client.max-retries: 30
      yarn.timeline-service.client.retry-interval-ms: 1000
      yarn.timeline-service.http-authentication.proxyuser.root.hosts: '{{ ambari_host }}'
      yarn.timeline-service.store-class: org.apache.hadoop.yarn.server.timeline.EntityGroupFSTimelineStore
      yarn.timeline-service.bind-host: 0.0.0.0
      yarn.nodemanager.container-metrics.unregister-delay-ms: 60000
      yarn.timeline-service.generic-application-history.store-class: org.apache.hadoop.yarn.server.applicationhistoryservice.NullApplicationHistoryStore
      yarn.resourcemanager.fs.state-store.uri:
      yarn.nodemanager.linux-container-executor.cgroups.hierarchy: hadoop-yarn
      yarn.resourcemanager.recovery.enabled: 'true'
      yarn.resourcemanager.scheduler.address: '%HOSTGROUP::host_group_1%:8030'
      yarn.timeline-service.leveldb-timeline-store.start-time-write-cache-size: 10000
      yarn.timeline-service.ttl-ms: 2678400000
      yarn.nodemanager.health-checker.script.timeout-ms: 60000
      yarn.log.server.url: 'http://%HOSTGROUP::host_group_1%:19888/jobhistory/logs'
      yarn.timeline-service.entity-group-fs-store.group-id-plugin-classes: 'org.apache.tez.dag.history.logging.ats.TimelineCachePluginImpl'
      yarn.resourcemanager.address: '%HOSTGROUP::host_group_1%:8050'
      yarn.timeline-service.recovery.enabled: 'true'
      yarn.resourcemanager.scheduler.monitor.enable: 'false'
      hadoop.registry.rm.enabled: 'true'
      yarn.resourcemanager.bind-host: 0.0.0.0
      yarn.nodemanager.log-aggregation.num-log-files-per-app: 30
      yarn.nodemanager.admin-env: MALLOC_ARENA_MAX=$MALLOC_ARENA_MAX
      yarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size: 10
      yarn.acl.enable: 'false'
      yarn.resourcemanager.ha.enabled: 'false'
      yarn.client.nodemanager-connect.retry-interval-ms: 10000
      yarn.timeline-service.version: 1.5
      yarn.nodemanager.linux-container-executor.resources-handler.class: org.apache.hadoop.yarn.server.nodemanager.util.DefaultLCEResourcesHandler
      yarn.timeline-service.leveldb-timeline-store.read-cache-size: 104857600
      yarn.nodemanager.local-dirs: /hadoop/yarn/local
      yarn.timeline-service.leveldb-timeline-store.path: /hadoop/yarn/timeline
      yarn.nodemanager.recovery.enabled: 'true'
      yarn.resourcemanager.zk-timeout-ms: 10000
      yarn.resourcemanager.am.max-attempts: 2
      yarn.resourcemanager.state-store.max-completed-applications: ${yarn.resourcemanager.max-completed-applications}
      yarn.nodemanager.linux-container-executor.cgroups.mount: 'false'
      yarn.node-labels.fs-store.root-dir: /system/yarn/node-labels
      yarn.node-labels.fs-store.retry-policy-spec: 2000, 500
      yarn.nodemanager.aux-services.mapreduce_shuffle.class: org.apache.hadoop.mapred.ShuffleHandler
      yarn.log-aggregation-enable: 'true'
      yarn.resourcemanager.work-preserving-recovery.enabled: 'true'
      yarn.resourcemanager.store.class: org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore
      yarn.timeline-service.http-authentication.proxyuser.root.groups: '*'
      yarn.timeline-service.leveldb-state-store.path: /hadoop/yarn/timeline
      yarn.timeline-service.entity-group-fs-store.done-dir: /ats/done/
      yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage: 90
      hadoop.registry.zk.quorum: '%HOSTGROUP::host_group_1%:2181'
      yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds: 3600
      yarn.nodemanager.container-executor.class: org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor
      yarn.resourcemanager.nodes.exclude-path: /etc/hadoop/conf/yarn.exclude
      yarn.timeline-service.state-store-class: org.apache.hadoop.yarn.server.timeline.recovery.LeveldbTimelineStateStore
      yarn.nodemanager.bind-host: 0.0.0.0
      yarn.resourcemanager.hostname: '%HOSTGROUP::host_group_1%'
      yarn.resourcemanager.connect.retry-interval.ms: 30000
      yarn.timeline-service.webapp.address: '%HOSTGROUP::host_group_1%:8188'
      yarn.scheduler.minimum-allocation-mb: 1024
      yarn.timeline-service.entity-group-fs-store.summary-store: org.apache.hadoop.yarn.server.timeline.RollingLevelDBTimelineStore
      yarn.nodemanager.health-checker.interval-ms: 135000
      yarn.nodemanager.disk-health-checker.min-free-space-per-disk-mb: 1000
      yarn.resourcemanager.zk-retry-interval-ms: 1000
      yarn.nodemanager.remote-app-log-dir: /app-logs
      yarn.scheduler.maximum-allocation-mb: 8192
      yarn.nodemanager.vmem-check-enabled: 'false'
      yarn.timeline-service.entity-group-fs-store.scan-interval-seconds: 60
      yarn.resourcemanager.webapp.https.address: '%HOSTGROUP::host_group_1%:8090'
      yarn.timeline-service.webapp.https.address: '%HOSTGROUP::host_group_1%:8190'
      yarn.nodemanager.resource.percentage-physical-cpu-limit: 80
      yarn.nodemanager.vmem-pmem-ratio: 2.1
      yarn.nodemanager.log-aggregation.compression-type: gz
      yarn.resourcemanager.work-preserving-recovery.scheduling-wait-ms: 10000
      yarn.nodemanager.log-dirs: /hadoop/yarn/log
  - yarn-env:
      yarn_cgroups_enabled: 'false'
      yarn_user_nproc_limit: 65536
      yarn_log_dir_prefix: /var/log/hadoop-yarn
      apptimelineserver_heapsize: 1024
      yarn_user_nofile_limit: 32768
      is_supported_yarn_ranger: 'true'
      service_check.queue.name: default
      resourcemanager_heapsize: 1024
      yarn_pid_dir_prefix: /var/run/hadoop-yarn
      yarn_user: yarn
      min_user_id: 500
      yarn_heapsize: 1024
      nodemanager_heapsize: 1024
  - oozie-site:
      oozie.base.url: 'http://%HOSTGROUP::host_group_1%:11000/oozie'
      oozie.service.URIHandlerService.uri.handlers: org.apache.oozie.dependency.FSURIHandler,org.apache.oozie.dependency.HCatURIHandler
      oozie.service.HadoopAccessorService.kerberos.enabled: 'false'
      oozie.action.retry.interval: 30
      oozie.authentication.simple.anonymous.allowed: 'true'
      oozie.service.JPAService.jdbc.username: oozie
      oozie.credentials.credentialclasses: hcat=org.apache.oozie.action.hadoop.HCatCredentials,hive2=org.apache.oozie.action.hadoop.Hive2Credentials
      oozie.services.ext: "\n      org.apache.oozie.service.JMSAccessorService,org.apache.oozie.service.PartitionDependencyManagerService,org.apache.oozie.service.HCatAccessorService"
      oozie.service.JPAService.jdbc.driver: org.apache.derby.jdbc.EmbeddedDriver
      oozie.authentication.type: simple
      oozie.service.AuthorizationService.security.enabled: 'true'
      oozie.db.schema.name: oozie
      oozie.service.JPAService.jdbc.password: oozie
  - capacity-scheduler:
      capacity-scheduler: null
      yarn.scheduler.capacity.root.accessible-node-labels: '*'
      yarn.scheduler.capacity.default.minimum-user-limit-percent: 100
      yarn.scheduler.capacity.maximum-am-resource-percent: 0.2
      yarn.scheduler.capacity.root.acl_administer_queue: '*'
      yarn.scheduler.capacity.root.default.acl_administer_jobs: '*'
      yarn.scheduler.capacity.resource-calculator: org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator
      yarn.scheduler.capacity.root.default.capacity: 100
      yarn.scheduler.capacity.root.default.user-limit-factor: 1
      yarn.scheduler.capacity.root.queues: default
      yarn.scheduler.capacity.root.capacity: 100
      yarn.scheduler.capacity.root.default.acl_submit_applications: '*'
      yarn.scheduler.capacity.root.default.maximum-capacity: 100
      yarn.scheduler.capacity.node-locality-delay: 40
      yarn.scheduler.capacity.maximum-applications: 10000
      yarn.scheduler.capacity.root.default.state: RUNNING
  - mapred-site:
      mapreduce.map.speculative: 'false'
      mapreduce.jobhistory.recovery.store.class: org.apache.hadoop.mapreduce.v2.hs.HistoryServerLeveldbStateStoreService
      mapreduce.job.counters.max: 130
      mapreduce.reduce.log.level: INFO
      mapreduce.shuffle.port: 13562
      yarn.app.mapreduce.am.admin-command-opts: -Dhdp.version=${hdp.version}
      mapreduce.job.emit-timeline-data: 'false'
      mapreduce.jobhistory.recovery.enable: 'true'
      mapreduce.map.log.level: INFO
      yarn.app.mapreduce.am.staging-dir: /user
      mapreduce.reduce.shuffle.merge.percent: 0.66
      mapreduce.output.fileoutputformat.compress: 'false'
      mapreduce.admin.map.child.java.opts: -server -XX:NewRatio=8 -Djava.net.preferIPv4Stack=true -Dhdp.version=${hdp.version}
      mapreduce.job.reduce.slowstart.completedmaps: 0.05
      mapreduce.jobhistory.http.policy: HTTP_ONLY
      mapreduce.job.queuename: default
      mapreduce.application.framework.path: /hdp/apps/${hdp.version}/mapreduce/mapreduce.tar.gz#mr-framework
      mapreduce.application.classpath: $PWD/mr-framework/hadoop/share/hadoop/mapreduce/*:$PWD/mr-framework/hadoop/share/hadoop/mapreduce/lib/*:$PWD/mr-framework/hadoop/share/hadoop/common/*:$PWD/mr-framework/hadoop/share/hadoop/common/lib/*:$PWD/mr-framework/hadoop/share/hadoop/yarn/*:$PWD/mr-framework/hadoop/share/hadoop/yarn/lib/*:$PWD/mr-framework/hadoop/share/hadoop/hdfs/*:$PWD/mr-framework/hadoop/share/hadoop/hdfs/lib/*:$PWD/mr-framework/hadoop/share/hadoop/tools/lib/*:/usr/hdp/${hdp.version}/hadoop/lib/hadoop-lzo-0.6.0.${hdp.version}.jar:/etc/hadoop/conf/
      mapreduce.reduce.java.opts: -Xmx1638m
      mapreduce.map.output.compress: 'false'
      mapreduce.reduce.input.buffer.percent: 0.0
      mapreduce.jobhistory.intermediate-done-dir: /mr-history/tmp
      yarn.app.mapreduce.am.log.level: INFO
      mapreduce.reduce.shuffle.fetch.retry.interval-ms: 1000
      mapreduce.reduce.shuffle.input.buffer.percent: 0.7
      mapreduce.reduce.speculative: 'false'
      mapreduce.output.fileoutputformat.compress.type: BLOCK
      mapreduce.task.io.sort.mb: 859
      mapreduce.cluster.administrators:  hadoop
      mapreduce.reduce.shuffle.fetch.retry.timeout-ms: 30000
      mapreduce.jobhistory.address: '%HOSTGROUP::host_group_1%:10020'
      mapreduce.map.sort.spill.percent: 0.7
      mapreduce.map.memory.mb: 1536
      mapreduce.admin.reduce.child.java.opts: -server -XX:NewRatio=8 -Djava.net.preferIPv4Stack=true -Dhdp.version=${hdp.version}
      mapreduce.jobhistory.bind-host: 0.0.0.0
      mapreduce.task.timeout: 300000
      mapreduce.admin.user.env: LD_LIBRARY_PATH=/usr/hdp/${hdp.version}/hadoop/lib/native:/usr/hdp/${hdp.version}/hadoop/lib/native/Linux-amd64-64
      mapreduce.am.max-attempts: 2
      mapreduce.reduce.memory.mb: 2048
      mapreduce.framework.name: yarn
      mapreduce.reduce.shuffle.parallelcopies: 30
      mapreduce.jobhistory.done-dir: /mr-history/done
      mapreduce.jobhistory.webapp.address: '%HOSTGROUP::host_group_1%:19888'
      mapreduce.reduce.shuffle.fetch.retry.enabled: 1
      mapreduce.task.io.sort.factor: 100
      mapreduce.jobhistory.recovery.store.leveldb.path: /hadoop/mapreduce/jhs
      yarn.app.mapreduce.am.command-opts: -Xmx819m -Dhdp.version=${hdp.version}
      mapreduce.map.java.opts: -Xmx1228m
      yarn.app.mapreduce.am.resource.mb: 1024
  - hive-site:
      javax.jdo.option.ConnectionPassword: HIVE_CLIENT,WEBHCAT_SERVER,HCAT,CONFIG_DOWNLOAD
      hive.exec.reducers.bytes.per.reducer: 67108864
      hive.metastore.pre.event.listeners: org.apache.hadoop.hive.ql.security.authorization.AuthorizationPreEventListener
      hive.optimize.reducededuplication: 'true'
      hive.metastore.sasl.enabled: 'false'
      hive.vectorized.execution.enabled: 'true'
      hive.security.authorization.manager: org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdConfOnlyAuthorizerFactory
      hive.auto.convert.join.noconditionaltask: 'true'
      hive.exec.orc.compression.strategy: SPEED
      hive.server2.allow.user.substitution: 'true'
      hive.limit.pushdown.memory.usage: 0.04
      hive.merge.rcfile.block.level: 'true'
      hive.stats.fetch.column.stats: 'true'
      hive.tez.dynamic.partition.pruning: 'true'
      hive.exec.max.dynamic.partitions.pernode: 2000
      hive.exec.orc.default.compress: ZLIB
      hive.merge.mapredfiles: 'false'
      hive.compactor.abortedtxn.threshold: 1000
      hive.map.aggr: 'true'
      hive.tez.dynamic.partition.pruning.max.data.size: 104857600
      hive.compactor.initiator.on: 'false'
      hive.smbjoin.cache.rows: 10000
      hive.exec.max.dynamic.partitions: 5000
      hive.auto.convert.join: 'true'
      hive.server2.support.dynamic.service.discovery: 'true'
      hive.tez.log.level: INFO
      hive.compactor.worker.timeout: 86400L
      hive.metastore.authorization.storage.checks: 'false'
      hive.merge.mapfiles: 'true'
      hive.exec.post.hooks: org.apache.hadoop.hive.ql.hooks.ATSHook
      hive.server2.transport.mode: binary
      hive.server2.thrift.http.path: cliservice
      hive.enforce.sortmergebucketmapjoin: 'true'
      hive.metastore.execute.setugi: 'true'
      hive.tez.smb.number.waves: 0.5
      hive.server2.authentication.spnego.keytab: HTTP/_HOST@EXAMPLE.COM
      hive.zookeeper.quorum: '%HOSTGROUP::host_group_1%:2181'
      hive.mapjoin.bucket.cache.size: 10000
      hive.metastore.kerberos.principal: hive/_HOST@EXAMPLE.COM
      hive.tez.auto.reducer.parallelism: 'true'
      hive.security.metastore.authorization.manager: org.apache.hadoop.hive.ql.security.authorization.StorageBasedAuthorizationProvider
      datanucleus.autoCreateSchema: 'false'
      datanucleus.fixedDatastore: 'true'
      hive.compute.query.using.stats: 'true'
      hive.security.authorization.enabled: 'false'
      hive.server2.thrift.sasl.qop: auth
      hive.merge.orcfile.stripe.level: 'true'
      hive.orc.splits.include.file.footer: 'false'
      hive.exec.compress.output: 'false'
      hive.user.install.directory: /user/
      hive.prewarm.enabled: 'false'
      hive.compactor.delta.num.threshold: 10
      hive.orc.compute.splits.num.threads: 10
      hive.vectorized.groupby.checkinterval: 4096
      hive.txn.manager: org.apache.hadoop.hive.ql.lockmgr.DummyTxnManager
      datanucleus.cache.level2.type: none
      hive.map.aggr.hash.percentmemory: 0.5
      hive.optimize.bucketmapjoin: 'true'
      hive.tez.max.partition.factor: 2.0
      hive.server2.thrift.port: 10000
      hive.exec.failure.hooks: org.apache.hadoop.hive.ql.hooks.ATSHook
      hive.exec.compress.intermediate: 'false'
      hive.exec.max.created.files: 100000
      hive.mapred.reduce.tasks.speculative.execution: 'false'
      hive.vectorized.groupby.flush.percent: 0.1
      hive.metastore.client.socket.timeout: 1800s
      hive.server2.tez.initialize.default.sessions: 'false'
      atlas.hook.hive.minThreads: 1
      hive.stats.autogather: 'true'
      hive.optimize.sort.dynamic.partition: 'false'
      hive.txn.max.open.batch: 1000
      hive.default.fileformat: TextFile
      hive.mapjoin.optimized.hashtable: 'true'
      hive.vectorized.groupby.maxentries: 100000
      hive.compactor.check.interval: 300L
      hive.security.authenticator.manager: org.apache.hadoop.hive.ql.security.ProxyUserAuthenticator
      hive.security.metastore.authorization.auth.reads: 'true'
      hive.compactor.delta.pct.threshold: 0.1f
      hive.vectorized.execution.reduce.enabled: 'false'
      javax.jdo.option.ConnectionDriverName: com.mysql.jdbc.Driver
      hive.stats.dbclass: fs
      hive.exec.parallel: 'false'
      hive.compactor.worker.threads: 0
      hive.exec.submitviachild: 'false'
      hive.fetch.task.conversion: more
      hive.server2.authentication: NONE
      hive.map.aggr.hash.force.flush.memory.threshold: 0.9
      hive.merge.tezfiles: 'false'
      hive.metastore.cache.pinobjtypes: Table,Database,Type,FieldSchema,Order
      hive.optimize.index.filter: 'true'
      hive.server2.authentication.spnego.principal: /etc/security/keytabs/spnego.service.keytab
      hive.convert.join.bucket.mapjoin.tez: 'false'
      hive.metastore.warehouse.dir: /apps/hive/warehouse
      hive.execution.engine: tez
      atlas.hook.hive.maxThreads: 1
      hive.tez.dynamic.partition.pruning.max.event.size: 1048576
      hive.cbo.enable: 'true'
      hive.exec.orc.encoding.strategy: SPEED
      hive.optimize.constant.propagation: 'true'
      hive.tez.container.size: 1024
      hive.metastore.connect.retries: 24
      hive.optimize.reducededuplication.min.reducer: 4
      hive.tez.input.format: org.apache.hadoop.hive.ql.io.HiveInputFormat
      hive.cluster.delegation.token.store.zookeeper.connectString: '%HOSTGROUP::host_group_1%:2181'
      hive.metastore.uris: 'thrift://%HOSTGROUP::host_group_1%:9083'
      hive.server2.max.start.attempts: 5
      hive.exec.dynamic.partition.mode: strict
      hive.server2.thrift.max.worker.threads: 500
      hive.server2.use.SSL: 'false'
      hive.tez.java.opts: -server -Djava.net.preferIPv4Stack=true -XX:NewRatio=8 -XX:+UseNUMA -XX:+UseG1GC -XX:+ResizeTLAB -XX:+PrintGCDetails -verbose:gc -XX:+PrintGCTimeStamps
      hive.exec.submit.local.task.via.child: 'true'
      hive.optimize.null.scan: 'true'
      hive.exec.orc.default.stripe.size: 67108864
      hive.limit.optimize.enable: 'true'
      hive.cluster.delegation.token.store.zookeeper.znode: /hive/cluster/delegation
      hive.exec.pre.hooks: org.apache.hadoop.hive.ql.hooks.ATSHook
      hive.cluster.delegation.token.store.class: org.apache.hadoop.hive.thrift.ZooKeeperTokenStore
      ambari.hive.db.schema.name: hive
      hive.zookeeper.client.port: 2181
      hive.enforce.sorting: 'true'
      hive.tez.cpu.vcores: -1
      hive.metastore.client.connect.retry.delay: 5s
      hive.server2.tez.default.queues: default
      hive.server2.tez.sessions.per.default.queue: 1
      hive.server2.thrift.http.port: 10001
      hive.server2.logging.operation.log.location: /tmp/hive/operation_logs
      javax.jdo.option.ConnectionURL: 'jdbc:mysql://%HOSTGROUP::host_group_1%/hive?createDatabaseIfNotExist=true'
      hive.map.aggr.hash.min.reduction: 0.5
      hive.merge.size.per.task: 256000000
      hive.merge.smallfiles.avgsize: 16000000
      hive.exec.reducers.max: 1009
      hive.optimize.metadataonly: 'true'
      hive.fetch.task.conversion.threshold: 1073741824
      hive.prewarm.numcontainers: 3
      hive.tez.min.partition.factor: 0.25
      hive.auto.convert.join.noconditionaltask.size: 286331153
      hive.server2.logging.operation.enabled: 'true'
      hive.metastore.kerberos.keytab.file: /etc/security/keytabs/hive.service.keytab
      hive.exec.parallel.thread.number: 8
      hive.support.concurrency: 'false'
      javax.jdo.option.ConnectionUserName: hive
      hive.conf.restricted.list: hive.security.authenticator.manager,hive.security.authorization.manager,hive.users.in.admin.role
      hive.auto.convert.sortmerge.join.to.mapjoin: 'false'
      hive.fetch.task.aggr: 'false'
      hive.cli.print.header: 'false'
      hive.server2.table.type.mapping: CLASSIC
      hive.txn.timeout: 300
      hive.stats.fetch.partition.stats: 'true'
      hive.optimize.bucketmapjoin.sortedmerge: 'false'
      hive.security.metastore.authenticator.manager: org.apache.hadoop.hive.ql.security.HadoopDefaultMetastoreAuthenticator
      hive.server2.enable.doAs: 'true'
      hive.server2.zookeeper.namespace: hiveserver2
      hive.default.fileformat.managed: TextFile
      hive.enforce.bucketing: 'false'
      hive.exec.scratchdir: /tmp/hive
      hive.exec.dynamic.partition: 'true'
      hive.metastore.server.max.threads: 100000
      hive.metastore.failure.retries: 24
      hive.auto.convert.sortmerge.join: 'true'
      hive.zookeeper.namespace: hive_zookeeper_namespace
  - tez-site:
      tez.am.launch.cmd-opts: -XX:+PrintGCDetails -verbose:gc -XX:+PrintGCTimeStamps -XX:+UseNUMA -XX:+UseG1GC -XX:+ResizeTLAB
      tez.runtime.sorter.class: PIPELINED
      tez.counters.max.groups: 3000
      tez.am.view-acls: '*'
      tez.runtime.shuffle.memory.limit.percent: 0.25
      tez.staging-dir: /tmp/${user.name}/staging
      tez.am.container.reuse.locality.delay-allocation-millis: 250
      tez.runtime.compress: 'true'
      tez.am.am-rm.heartbeat.interval-ms.max: 250
      tez.am.container.idle.release-timeout-min.millis: 10000
      tez.task.launch.cmd-opts: -XX:+PrintGCDetails -verbose:gc -XX:+PrintGCTimeStamps -XX:+UseNUMA -XX:+UseG1GC -XX:+ResizeTLAB
      tez.lib.uris: /hdp/apps/${hdp.version}/tez/tez.tar.gz
      tez.counters.max: 10000
      tez.generate.debug.artifacts: 'false'
      tez.runtime.convert.user-payload.to.history-text: 'false'
      tez.shuffle-vertex-manager.max-src-fraction: 0.4
      tez.am.log.level: INFO
      tez.task.am.heartbeat.counter.interval-ms.max: 4000
      tez.am.container.idle.release-timeout-max.millis: 20000
      tez.am.resource.memory.mb: 2048
      tez.am.max.app.attempts: 2
      tez.cluster.additional.classpath.prefix: /usr/hdp/${hdp.version}/hadoop/lib/hadoop-lzo-0.6.0.${hdp.version}.jar:/etc/hadoop/conf/secure
      tez.am.container.reuse.non-local-fallback.enabled: 'false'
      tez.am.container.reuse.rack-fallback.enabled: 'true'
      tez.task.get-task.sleep.interval-ms.max: 200
      tez.runtime.io.sort.mb: 270
      tez.task.resource.memory.mb: 1024
      tez.runtime.optimize.local.fetch: 'true'
      tez.runtime.pipelined.sorter.sort.threads: 2
      tez.shuffle-vertex-manager.min-src-fraction: 0.2
      tez.session.am.dag.submit.timeout.secs: 600
      tez.session.client.timeout.secs: -1
      tez.am.launch.cluster-default.cmd-opts: -server -Djava.net.preferIPv4Stack=true -Dhdp.version=${hdp.version}
      tez.am.maxtaskfailures.per.node: 10
      tez.am.tez-ui.history-url.template: __HISTORY_URL_BASE__?viewPath=%2F%23%2Ftez-app%2F__APPLICATION_ID__
      tez.runtime.shuffle.fetch.buffer.percent: 0.6
      tez.task.launch.env: LD_LIBRARY_PATH=/usr/hdp/${hdp.version}/hadoop/lib/native:/usr/hdp/${hdp.version}/hadoop/lib/native/Linux-amd64-64
      tez.use.cluster.hadoop-libs: 'false'
      tez.queue.name: default
      tez.runtime.unordered.output.buffer.size-mb: 76
      tez.am.container.reuse.enabled: 'true'
      tez.grouping.split-waves: 1.7
      tez.grouping.max-size: 1073741824
      tez.task.launch.cluster-default.cmd-opts: -server -Djava.net.preferIPv4Stack=true -Dhdp.version=${hdp.version}
      tez.task.max-events-per-heartbeat: 500
      tez.history.logging.service.class: org.apache.tez.dag.history.logging.ats.ATSV15HistoryLoggingService
      tez.grouping.min-size: 16777216
      tez.task.generate.counters.per.io: 'true'
      tez.am.launch.env: LD_LIBRARY_PATH=/usr/hdp/${hdp.version}/hadoop/lib/native:/usr/hdp/${hdp.version}/hadoop/lib/native/Linux-amd64-64
      tez.runtime.compress.codec: org.apache.hadoop.io.compress.SnappyCodec
  - webhcat-site:
      templeton.zookeeper.hosts: '%HOSTGROUP::host_group_1%:2181'
      webhcat.proxyuser.root.groups: '*'
      webhcat.proxyuser.root.hosts: '{{ ambari_host }}'
      templeton.hadoop.queue.name: default
      templeton.hadoop: /usr/hdp/${hdp.version}/hadoop/bin/hadoop
      templeton.hive.extra.files: /usr/hdp/${hdp.version}/tez/conf/tez-site.xml,/usr/hdp/${hdp.version}/tez,/usr/hdp/${hdp.version}/tez/lib
      templeton.hcat.home: hive.tar.gz/hive/hcatalog
      templeton.override.enabled: 'false'
      templeton.hive.properties: 'hive.metastore.local=false,hive.metastore.uris=thrift://%HOSTGROUP::host_group_1%:9083,hive.metastore.sasl.enabled=false,hive.metastore.execute.setugi=true'
      templeton.python: '${env.PYTHON_CMD}'
      templeton.storage.class: org.apache.hive.hcatalog.templeton.tool.ZooKeeperStorage
      templeton.streaming.jar: hdfs:///hdp/apps/${hdp.version}/mapreduce/hadoop-streaming.jar
      templeton.hadoop.conf.dir: /etc/hadoop/conf
      templeton.hcat: /usr/hdp/${hdp.version}/hive/bin/hcat
      templeton.jar: /usr/hdp/${hdp.version}/hive/share/webhcat/svr/lib/hive-webhcat-*.jar
      templeton.port: 50111
      templeton.libjars: /usr/hdp/${hdp.version}/zookeeper/zookeeper.jar,/usr/hdp/${hdp.version}/hive/lib/hive-common.jar
      templeton.hive.path: hive.tar.gz/hive/bin/hive
      templeton.exec.timeout: 60000
      templeton.sqoop.home: sqoop.tar.gz/sqoop
      templeton.sqoop.archive: hdfs:///hdp/apps/${hdp.version}/sqoop/sqoop.tar.gz
      templeton.hive.archive: hdfs:///hdp/apps/${hdp.version}/hive/hive.tar.gz
      templeton.hive.home: hive.tar.gz/hive
      templeton.pig.archive: hdfs:///hdp/apps/${hdp.version}/pig/pig.tar.gz
      templeton.pig.path: pig.tar.gz/pig/bin/pig
      templeton.sqoop.path: sqoop.tar.gz/sqoop/bin/sqoop
  - hivemetastore-site:
      hive.service.metrics.hadoop2.component: hivemetastore
      hive.metastore.metrics.enabled: 'true'
      hive.service.metrics.reporter: JSON_FILE, JMX, HADOOP2
      hive.service.metrics.file.location: /var/log/hive/hivemetastore-report.json
  - hadoop-env:
      hadoop_heapsize: 1024
      proxyuser_group: users
      hadoop_root_logger: INFO,RFA
      dtnode_heapsize: 1024m
      namenode_backup_dir: /tmp/upgrades
      hdfs_user: hdfs
      hadoop_pid_dir_prefix: /var/run/hadoop
      hdfs_log_dir_prefix: /var/log/hadoop
      namenode_opt_newsize: 128m
      namenode_heapsize: 1024m
      hdfs_tmp_dir: /tmp
      namenode_opt_maxpermsize: 256m
      nfsgateway_heapsize: 1024
      hdfs_user_nofile_limit: 128000
      keyserver_host: ' '
      keyserver_port: ''
      hdfs_user_nproc_limit: 65536
      namenode_opt_maxnewsize: 128m
      namenode_opt_permsize: 128m
  - zookeeper-env:
      zk_log_dir: /var/log/zookeeper
      zk_user: zookeeper
      zk_pid_dir: /var/run/zookeeper
  - mapred-env:
      jobhistory_heapsize: 900
      mapred_user_nofile_limit: 32768
      mapred_user: mapred
      mapred_user_nproc_limit: 65536
      mapred_pid_dir_prefix: /var/run/hadoop-mapreduce
      mapred_log_dir_prefix: /var/log/hadoop-mapreduce
  - hive-env:
      hive_database: New MySQL Database
      hcat_log_dir: /var/log/webhcat
      hive_exec_orc_storage_strategy: SPEED
      webhcat_user: hcat
      hive_log_dir: /var/log/hive
      hive_user: hive
      hive_security_authorization: None
      hive_user_nproc_limit: 16000
      hive.metastore.heapsize: 1488
      hive_timeline_logging_enabled: 'true'
      hive_txn_acid: off
      hive.client.heapsize: 1024
      hive.heapsize: 4466
      hive_database_name: hive
      hive_database_type: mysql
      hive_user_nofile_limit: 32000
      hive_pid_dir: /var/run/hive
      hcat_user: hcat
      hive_ambari_database: MySQL
      hcat_pid_dir: /var/run/webhcat
blueprint:
  stack_name: HDP
  stack_version: "{{ hdp_stack }}"
  groups:
    - name : host_group_1
      cardinality: 1
      configurations: []
      components: "{{ cr_components }}"
      hosts: "{{ hdp_host_group }}"
